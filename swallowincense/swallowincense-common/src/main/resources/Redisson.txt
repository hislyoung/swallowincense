缓存穿透、雪崩、击穿
缓存穿透：
    查询一个不存在的数据，由于缓存不命中，查询数据库，数据库中也不存在，没有将此次查询的null结果放入到缓存中，导致不存在的数据
总是要查库，失去了缓存的意义。
    问题：利用不存在的数据进行攻击，数据库瞬时压力增大，最终导致崩溃
    解决：null结果缓存，并加入短暂的过期时间
缓存雪崩：
    缓存雪崩是指在我们设置缓存是key采用了相同的过期时间，导致缓存在某一时刻同时失效，请求全部落到DB上，DB瞬时压力过大
    解决：原有失效时间的基础上增加一个随机值，比如1-5分钟随机，这样每一个缓存的过期时间的重复率就会降低，就很难引发集体失效问题
缓存击穿：
    对于一些设置了过期时间的key，如果这些key可能会在某些时间点被超高并发的访问，是一种“热点”数据。这个key在大量请求的时候恰巧
失效，那么说有的查询将落到DB，此为缓存击穿。
    解决：加锁，大量的并发只让一个去查，其他请求等待，查到以后释放锁，其他请求获得锁之后，第一个查询会将数据缓存，因此不用去DB

整合redis
    引入启动场景
    配置host 密码 端口等信息
    使用stringRedisTemplate
内存泄露问题：
    堆外内存溢出（OutOfDirectMemoryError）默认使用lettuce作为默认的客户端，lettuce使用netty进行网络通信
    lettuce有Bug，netty如果没有指定堆外内存，默认会使用Xmx做堆外内存
    netty在PlatformDependent类的incrementMemoryCounter方法中有自己的内存计数
    可以通过这个命令设置-Dio.netty.maxDirectMemory，不设置默认使用Xmx的虚拟机参数
解决方案：不能只是用-Dio.netty.maxDirectMemory调大内存
    升级lettuce客户端
    切换使用jedis
redisTemplate与lettuce、jedis的关系
    lettuce、jedis封装底层的操作
    redisTemplate是对lettuce、jedis进一步封装
    @Import({ LettuceConnectionConfiguration.class, JedisConnectionConfiguration.class })
    JUC与synchronized本地锁适合单体应用，不适合分布式情况，分布式锁会变慢

Redis实现分布式锁(原子操作)：
    redis原生的setnx命令（不存在则添加）
    operations.setIfAbsent()
引发问题：
    1、设置锁，如果在执行业务的时候发生异常或者宕机，没有释放锁，引发死锁问题
    2、删除锁，如果业务超长，并且怕死锁设置了过期时间太短，要删锁的时候自己的实际已经过期，会删除别人的锁
解决方法：
    设置锁问题解决，设置一个自动过期时间
    解除锁问题解决，占锁的时候，值指定为UUID，每个人匹配自己的才可以删除成功

Redisson实现分布式锁：实现了JUC的接口，使用方法同JUC，底层一样是发送lua脚本保证原子性操作,注意锁key命名的粒度
    实现可重入锁（Reentrant Lock）：持有同一把锁的对象不用锁等待可直接执行，避免竞争同一把锁而互相等待造成死锁
    Rlock只要锁名字一样就是一把锁，阻塞式等待
    1、锁的自动续期，不用担心锁过期被删掉（看门狗机制，默认30S，条件是1/3则续期）
    2、加锁的业务只要运行完成，就不会续期，不手动解锁，锁会在30S后自动删除
    3、默认是非公平锁
    4、读写锁:写数据加写锁，读数据加读锁，写数据排他锁，读数据共享锁
     w+r 等待w
     w+w 阻塞等待
     r+w 有读锁，写也需要等待
     r+r 无锁
    5、闭锁 例子，学生放假
    6、信号量 例子，占车位

缓存一致性：即缓存数据如何与数据库保持一致性
    解决方案：双写模式-修改数据库的同时修改缓存
              失效模式-修改数据库之后删除缓存
    存在的问题：双写模式-一号线程修改数据库后，由于各种原因没有即时修改缓存，二号线程全部修改，一号线程添加缓存，二号线程的缓存修改被覆盖
               失效模式-一号线程修改后删缓存，在二号线程修改到删缓存之间，三号线程进来读了一号缓存的数据，二号删除缓存，三号写缓存
    解决方案：双写模式-加锁，或者评估是否允许暂时的缓存不一致问题
             失效模式-加锁

总结：
    无论是双写模式还是失效模式，都会导致数据的暂时不一致问题，即多个实例同时更新会出事
        1、如果是用户维度（订单，用户）数据，并发几率很小，不用考虑这个问题，缓存数据加上过期时间，每隔一段时间触发主动更新
        2、如果是菜单、商品介绍等数据，实时性要求也可以不考虑（数据不一致性容忍度较高）
        3、缓存数据+过期时间也足够解决大部分的业务场景
        4、加锁，读写锁
        5、对频繁读写的数据考虑是否加缓存
        6、canal订阅binlog更新缓存，canal数据异构（大数据杀熟）

